---
order: 100
---
# Preliminaries
## Distribution of Hashes
A proper hash function should be random in the sense that each output bit cannot be predicted from the input and also cannot be predicted from other bits in its output. Therefore with the interpretation of a hash as a number in $[0,1)$ we can model the Verushash v2.1 $X(h)$ and the Sha256t $Y(h)$ of a header as samples of [uniform](https://en.wikipedia.org/wiki/Continuous_uniform_distribution) [random variable](https://en.wikipedia.org/wiki/Random_variable) on $[0,1]$. Since we use two different hash functions we can model the vector $(X(h),Y(h))$ as two [independent](https://en.wikipedia.org/wiki/Independence_(probability_{\tau}heory)) realization of a uniform random variable on $[0,1]$. This means that the [joint distribution](https://en.wikipedia.org/wiki/Joint_probability_distribution) is the [product measure](https://en.wikipedia.org/wiki/Product_measure), i.e. the uniform distribution on $[0,1]^2$.

We therefore define the [random vector](https://en.wikipedia.org/wiki/Multivariate_random_variable) $(X,Y)$ to have this uniform probability distribution on $[0,1]$. Keep in mind that this random vector just models the Verushash v2.1 and Sha256t hashes (interpreted as numbers in $[0,1]$) of a block header in a probability-theoretic setting. 

## Acceptance region

Recall the the two conditions to solve a block.
[!ref](/Janushash/condition-to-solve-a-block.md)
An equivalent formulation is to require that $(X(h),Y(h))$ must be an element of the *acceptance region* $A_{\tau}\subset [0,1]^2$ defined as

$$
A_{\tau} := \big\lbrace (x,y) \in [0,1]^2\big \vert  xy^{0.7} < \tau \land y>c\big\rbrace
$$


The target controls the difficulty, obviously if the target is decreased then it is more difficulty to mine a block.

### More insight on the log scale

If we apply the logarithmic transformation on the acceptance region $A_{\tau}$, the condition

$$ 
xy^{0.7} <\tau\land y>c 
$$

can be reformulated as

$$ 
-\log(x)+0.7(-\log(y)) >-\log(\tau)\land -\log(y)<-\log(c) 
$$

Recall that $x$ and $y$ are less than 1. This means $-\log(x)$ and $-\log(y)$ are positive. We can therefore visualize the acceptance region $A_{\tau}$ in the first [quadrant](https://en.wikipedia.org/wiki/Quadrant_(plane_geometry)) of a [Cartesian coordinate system](https://en.wikipedia.org/wiki/Cartesian_coordinate_system) representing $-\log(x)$ and $-\log(y)$ along its axes.

The following figure depicts the situation in log scale, the acceptance region $A_{\tau}$ is colored light blue:

<p align="center">
  <img src="/img/acceptance_region.svg" alt="Acceptance Region"/>
</p>

## Pushforward measure on log scale.

On the log scale we consider the transformed vector $(-\log(X),-\log(Y))$. The probability distribution of this transformed vector is the [pushforward measure](https://en.wikipedia.org/wiki/Pushforward_measure) of $(X,Y)$ through the map $g: [0,1]^2 \to \mathbb{R}_{\ge0}^2, (x,y)\mapsto(-\log(x),-\log(y))$. Note that by independence of $X$ and $Y$

$$
\forall x,y\ge 0:\quad \mathbb{P}\big[-\log(X)\le x\land -\log(Y)\le y\big]=
\mathbb{P}\big[X\le e^{-x}\land Y\le e^{-y}\big]=e^{-(x+y)}.
$$

Since the [Borel $\sigma$-algebra](https://en.wikipedia.org/wiki/Borel_set) on $\mathbb{R}_{\ge 0}^2$ is generated by the sets $[0,x]\times [0,y], x,y\in\mathbb{R}_{\ge0}$ this proves that the pushforward measure is the product measure of two identical [exponential distributions](https://en.wikipedia.org/wiki/Exponential_distribution).

With this info we can do probability-theoretic calculations on the log scale.
